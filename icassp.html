<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link
      href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css"
      rel="stylesheet"
    />
    <title>
      Audio Samples from "HYPERPARAMETER TUNING OF TEXT-TO-SPEECH MODELS FOR
      EMOTIONAL SPEECH SYNTHESIS"
    </title>
  </head>
  <body class="bg-gray-100">
    <section class="p-8 md:p-16">
      <div class="max-w-screen-lg mx-auto">
        <h1
          class="text-2xl md:text-4xl font-bold text-center text-blue-600 mb-4"
        >
          Audio Samples from "HYPERPARAMETER TUNING OF TEXT-TO-SPEECH MODELS FOR
          EMOTIONAL SPEECH SYNTHESIS"
        </h1>
        <!-- <p class="text-lg text-gray-700 mb-4">
          Paper: <span class="font-bold">Paper Name</span>
        </p> -->
        <p class="text-lg text-gray-700 mb-4">
          Authors:
          <span class="font-bold"
            >Author Names: Abhigyan Basak, Metta Venkata Srujan, Harshal Pravin
            Kshirsagar, M Prerana Rao, Saurabh Agrawal, Manjula Shenoyk K, Gopal
            Kumar Agrawal, Rishabh Jain</span
          >
        </p>
        <div class="text-lg text-gray-700">
          <p class="font-bold mb-2">Abstract:</p>
          <p>
            In recent years, significant advancements in emotional speech
            synthesis have emerged, driven by deep learning-based models and
            vocoders. This paper conducts experiments on vital text-to-speech
            components, namely text-to-speech models (Tacotron 2) and vocoders
            (HiFi-GAN), utilizing a custom-recorded dataset featuring emotional
            speech samples with Indian accents across five distinct emotional
            states to enhance emotional speech synthesis quality. We initially
            employ a Tacotron 2 model with WaveGlow vocoder and subsequently
            introduce the Comprehensive Tacotron Model and the HiFiGAN vocoder.
            Throughout the study, we experiment with hyperparameters, activation
            functions, loss functions, and kernel sizes to optimize HiFi-GAN's
            performance on emotional data. This work contributes to advancing
            emotional speech synthesis in Indian accents and offers valuable
            insights into the effectiveness of different vocoder configurations.
          </p>
        </div>
      </div>
    </section>

    <section class="p-8 md:p-16">
      <div class="max-w-screen-lg mx-auto">
        <!-- <h1
          class="text-xl md:text-3xl font-bold text-center text-blue-600 mb-4"
        >
          Title for Section 2
        </h1> -->
        <p class="text-lg text-gray-700 mb-4">
          "I love the enthusiasm inherent in the scream. I never saw anything
          wrong with it. Not to mention the most innocent, innocuous dancing
          video ever."
        </p>
        <audio controls class="mb-4">
          <source src="audios/excitement/866.wav" type="audio/mpeg" />
          Your browser does not support the audio element.
        </audio>
        <!-- <p class="text-lg text-gray-700">
          Audio sample:
          <a
            href="your-audio-sample.mp3"
            download
            class="text-blue-600 font-bold"
            >Download Audio</a
          >
        </p> -->
      </div>
    </section>
  </body>
</html>
